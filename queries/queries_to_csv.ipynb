{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6571e1a1-64c0-4f01-86a7-38beff1451f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "PARENT_FOLDER = os.path.join(os.path.dirname(os.path.realpath(\"__file__\")), \"../\")\n",
    "sys.path.append(PARENT_FOLDER)\n",
    "\n",
    "import pandas as pd\n",
    "import lost.utils as u\n",
    "from datetime import datetime\n",
    "from lost.connection import con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a60ad5a4-e23e-498a-a3bd-908d981e351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime('01/01/2018')\n",
    "end_date = '2021-07-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7af426b3-4699-41db-8c1e-84d7d558cad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    select product_merch_classification2, count (product_merch_classification2) as frequency \n",
    "    from chewybi.products \n",
    "    group by product_merch_classification2 \n",
    "    order by frequency desc\n",
    "\"\"\"\n",
    "mc2_unique = pd.read_sql_query(query, con)\n",
    "mc2_unique.drop(28,0,inplace=True)\n",
    "mc2_unique['mc2'] = mc2_unique['product_merch_classification2'].str.replace('&','and')\n",
    "mc2_unique['mc2'] = mc2_unique['mc2'].str.replace(',','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b56599-2094-4cc5-87af-618e7ae84fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc2_unique.to_csv('../data/product_snowflake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226bb556-d851-4df8-9687-8b00ef3f9080",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(mc2_unique.shape[0]):\n",
    "    try:\n",
    "        print('Started {}'.format(mc2_unique.loc[i,'product_merch_classification2']))\n",
    "        args = {\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"class\": mc2_unique.loc[i,'product_merch_classification2'],\n",
    "        \"file\": mc2_unique.loc[i,'mc2'],\n",
    "        }\n",
    "\n",
    "        observation_period = (\n",
    "        datetime.combine(start_date, datetime.min.time()), \n",
    "        datetime.combine(end_date, datetime.min.time())\n",
    "        )\n",
    "\n",
    "        FILE_PATH = os.path.join(PARENT_FOLDER, \"data/V_{file}.pkl\".format(**args))\n",
    "        QUERY_PATH =  os.path.join(PARENT_FOLDER, \"sql/lost_mc2-v2.sql\")\n",
    "\n",
    "        if os.path.exists(FILE_PATH): \n",
    "            continue\n",
    "            df2 = pd.read_pickle(FILE_PATH)\n",
    "        else:\n",
    "            with open(QUERY_PATH, \"r\") as f:\n",
    "                script = f.read().format(**args)\n",
    "            df2 = u.snowflake_execute(script)\n",
    "            df2.to_pickle(FILE_PATH)\n",
    "    except:\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e02c3-e1f4-48cf-9e08-fdbe14e3f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "files = glob.glob(\"../data/V_*.pkl\")\n",
    "for f in files:\n",
    "    data = pd.read_pickle(f)\n",
    "    data['mc2'] = f.replace('../data/V_', '').replace('.pkl', '')\n",
    "    df = pd.concat([df,data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022cd698-5c63-43b2-909f-c603481fb4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"../data/V_all.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187bd5e9-3d84-427a-8b84-06017eb71aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        }\n",
    "\n",
    "query = \"\"\"\n",
    "        with base as (\n",
    "\n",
    "            select distinct\n",
    "            i.inventory_snapshot_snapshot_dt::date as date,\n",
    "            i.product_part_number as item,\n",
    "            p.product_merch_classification2 as mc2,\n",
    "            sum(i.inventory_snapshot_sellable_quantity) as total_quantity,\n",
    "            sum(i.inventory_snapshot_item_location_avg_daily_forecast_quantity) as forecast\n",
    "            from chewybi.inventory_snapshot as i\n",
    "            inner join chewybi.products as p\n",
    "            using (product_part_number)\n",
    "            where inventory_snapshot_snapshot_dt between '{start_date}' and '{end_date}'\n",
    "            and item_location_product_published_flag\n",
    "            and not item_location_product_discontinued_flag\n",
    "            group by 1,3,2\n",
    "\n",
    "        )\n",
    "\n",
    "        select \n",
    "            date_trunc('week',b.date::date), -- get week interval \n",
    "            b.mc2,\n",
    "            sum(case when total_quantity > 0 then 1 else 0 end) num_instock,\n",
    "            sum(case when total_quantity > 0 then 0 else 1 end) as oos,\n",
    "            count(item) as count,\n",
    "            sum(case when total_quantity > 0 then 0 else 1 end)/count(item) as oos_rate,\n",
    "            sum(case when total_quantity < 1 then b.forecast else 0 end) / sum(forecast) as weighted_oos_rate\n",
    "        from base as b\n",
    "        group by 1,2\n",
    "        \"\"\"\n",
    "\n",
    "query2 = '''\n",
    "   --- the query below can be used to look at the number of units ordered over a given period of time.  \n",
    "\n",
    "        select date_trunc('week',olm.order_line_released_dttm::date)\n",
    "        ,p.product_merch_classification2\n",
    "        ,sum(olm.order_line_quantity) as ordered_qty\n",
    "        ,sum(olm.order_line_total_price) as total_price\n",
    "        ,sum(case when o.order_auto_reorder_flag is true then olm.order_line_quantity else 0 end) as autoship_qty -- autoships are the orders which are on a subscription. you can play around with this to see which\n",
    "                                                                                                                -- types of items are more subscription havy than other products\n",
    "        from chewybi.order_line_measures olm -- this table has details about the units purchased on each order. each order has an order id and order line id. each order line id\n",
    "                                            -- is associated with one product, so we can the qty ordered for a given level of aggregation of products\n",
    "        join chewybi.products p using(product_key) --- this table has product information such as product classification, brand, etc. t is keyed at the product level\n",
    "        join chewybi.orders o using(order_key) -- this has order information, it is keyed at the order level\n",
    "        where 1=1 \n",
    "        and olm.order_line_released_dttm::date between date_trunc('week',TO_DATE({end_date}, 'YYYY-MM-DD')) - interval '4 years' and date_trunc('week',TO_DATE({end_date}, 'YYYY-MM-DD')) - interval '1 weeks' -- this is when the order was released to the warehouse to begin processing\n",
    "        and o.order_status not in ('X','J') -- these are canceled orders, we always want to remove them\n",
    "        group by 1,2\n",
    "        ;\n",
    "'''\n",
    "dfo_all = pd.read_sql_query(query.format(**args), con)\n",
    "oredered_all = pd.read_sql_query(query2.format(**args), con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c060bdc-bb1e-44c8-8b92-329868de9f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo_all.to_csv('../data/dfo_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965f1f87-e2c9-4ac0-bac7-1c7a80e6f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "oredered_all.to_csv('../data/oredered_all.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
